{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.models as models"
      ],
      "metadata": {
        "id": "TdeFQ47IYMUr"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('device:', device)"
      ],
      "metadata": {
        "id": "qtaYktpUYMS1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e02e2bf-bdb6-4979-c1b0-9e188834ea5f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv kaggle.json /root/.kaggle"
      ],
      "metadata": {
        "id": "azwWvH5bYMRJ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d gpiosenka/sports-classification"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neMbq-pzCAFL",
        "outputId": "50a09620-adca-47ce-8514-bb1fa2a1a3e3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/kaggle/api/kaggle_api_extended.py\", line 403, in authenticate\n",
            "    raise IOError('Could not find {}. Make sure it\\'s located in'\n",
            "OSError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip sports-classification.zip >> /dev/null"
      ],
      "metadata": {
        "id": "BX6OP-HKYX9r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15a011e0-ae50-4016-e2d1-74395af5a116"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open sports-classification.zip, sports-classification.zip.zip or sports-classification.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),  # Resize images to the desired size\n",
        "    transforms.ToTensor(),           # Convert images to tensors\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize images\n",
        "])"
      ],
      "metadata": {
        "id": "e3hVn6l3YX7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yI2Trtte171u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "4223f4a9-cbd4-4355-8d8f-d7ed9c514ea0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './train'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-7d5028d477c0>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train data loader and test data loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mis_valid_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     ):\n\u001b[0;32m--> 309\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    310\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    142\u001b[0m     ) -> None:\n\u001b[1;32m    143\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \"\"\"\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDatasetFolder\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \"\"\"\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './train'"
          ]
        }
      ],
      "source": [
        "# train data loader and test data loader\n",
        "dataset = ImageFolder(root='./train', transform=transform)\n",
        "\n",
        "batch_size = 128\n",
        "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_dataset = ImageFolder(root='./test', transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_return_test_accuracy(model, num_epochs=20, learning_rate=0.005):\n",
        "    \"\"\"Function to train a model on the training set and evaluate its accuracy on the test set\"\"\"\n",
        "    # Setup for training: using stochastic gradient descent for optimization\n",
        "    sgd_optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Iterative training process\n",
        "    for epoch in range(num_epochs):\n",
        "        for batch_index, (inputs, labels) in enumerate(train_loader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            sgd_optimizer.zero_grad()\n",
        "            predictions = model(inputs)\n",
        "            loss_value = criterion(predictions, labels)\n",
        "            loss_value.backward()\n",
        "            sgd_optimizer.step()\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            print(f'Training Epoch: {epoch + 1} \\tLoss: {loss_value.item():.6f}')\n",
        "\n",
        "    # Evaluating accuracy on the test dataset\n",
        "    correct_predictions = 0\n",
        "    all_samples = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            test_outputs = model(inputs)\n",
        "            _, preds = torch.max(test_outputs.data, 1)\n",
        "            all_samples += 1\n",
        "            correct_predictions += (preds == labels).sum().item()\n",
        "    accuracy_on_test = correct_predictions / all_samples\n",
        "    return accuracy_on_test"
      ],
      "metadata": {
        "id": "vRqm2QawXcuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=False)\n",
        "# modify the last layer to fit the number of classes 100\n",
        "model.classifier[6] = nn.Linear(4096, 100)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "qS0IxCwEig5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy = train_and_return_test_accuracy(model)\n",
        "print(f'Test accuracy: {test_accuracy} % ')"
      ],
      "metadata": {
        "id": "DTaPmfuGig1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Transfer learning\n"
      ],
      "metadata": {
        "id": "F2dPnOwVudA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_return_test_accuracy(model, total_epochs=20, step_lr=0.005):\n",
        "    \"\"\"Function for training a model on the training dataset and calculating its accuracy on a test dataset\"\"\"\n",
        "    # Setup for optimization with stochastic gradient descent\n",
        "    optimize = optim.SGD(model.parameters(), lr=step_lr, momentum=0.9)\n",
        "    calculate_loss = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Training loop\n",
        "    for current_epoch in range(total_epochs):\n",
        "        for batch_number, (input_data, labels) in enumerate(train_loader):\n",
        "            input_data = input_data.to(device)\n",
        "            labels = labels.to(device)\n",
        "            optimize.zero_grad()\n",
        "            prediction = model(input_data)\n",
        "            training_loss = calculate_loss(prediction, labels)\n",
        "            training_loss.backward()\n",
        "            optimize.step()\n",
        "        if (current_epoch + 1) % 5 == 0:\n",
        "            print(f'Training Epoch: {current_epoch + 1} \\tLoss: {training_loss.item():.6f}')\n",
        "\n",
        "    # Evaluation for accuracy on the test set\n",
        "    accurate_predictions = 0\n",
        "    total_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for input_data, labels in test_loader:\n",
        "            input_data = input_data.to(device)\n",
        "            labels = labels.to(device)\n",
        "            test_predictions = model(input_data)\n",
        "            _, highest_predictions = torch.max(test_predictions.data, 1)\n",
        "            total_predictions += 1\n",
        "            accurate_predictions += (highest_predictions == labels).sum().item()\n",
        "    accuracy_of_test = accurate_predictions / total_predictions\n",
        "    return accuracy_of_test\n"
      ],
      "metadata": {
        "id": "aEqkJrDzigu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transfer learning\n",
        "\n",
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True)\n",
        "# modify the last layer to fit the number of classes 100\n",
        "model.classifier[6] = nn.Linear(4096, 100)\n",
        "\n",
        "# freeze all feature layers\n",
        "for param in model.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "test_accuracy = train_and_return_test_accuracy(model)\n",
        "print(f'Test accuracy: {test_accuracy}')"
      ],
      "metadata": {
        "id": "FEO830KYwInt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Transfer learning based on vgg19 and resnet50"
      ],
      "metadata": {
        "id": "j14-PgThwoS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_return_test_accuracy(model, total_epochs=5, step_lr=0.005):\n",
        "    \"\"\"Function for training a model on the training dataset and calculating its accuracy on a test dataset\"\"\"\n",
        "    # Setup for optimization with stochastic gradient descent\n",
        "    optimize = optim.SGD(model.parameters(), lr=step_lr, momentum=0.9)\n",
        "    calculate_loss = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Training loop\n",
        "    for current_epoch in range(total_epochs):\n",
        "        for batch_number, (input_data, labels) in enumerate(train_loader):\n",
        "            input_data = input_data.to(device)\n",
        "            labels = labels.to(device)\n",
        "            optimize.zero_grad()\n",
        "            prediction = model(input_data)\n",
        "            training_loss = calculate_loss(prediction, labels)\n",
        "            training_loss.backward()\n",
        "            optimize.step()\n",
        "        if (current_epoch + 1) % 1 == 0:\n",
        "            print(f'Training Epoch: {current_epoch + 1} \\tLoss: {training_loss.item():.6f}')\n",
        "\n",
        "    # Evaluation for accuracy on the test set\n",
        "    accurate_predictions = 0\n",
        "    total_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for input_data, labels in test_loader:\n",
        "            input_data = input_data.to(device)\n",
        "            labels = labels.to(device)\n",
        "            test_predictions = model(input_data)\n",
        "            _, highest_predictions = torch.max(test_predictions.data, 1)\n",
        "            total_predictions += 1\n",
        "            accurate_predictions += (highest_predictions == labels).sum().item()\n",
        "    accuracy_of_test = accurate_predictions / total_predictions\n",
        "    return accuracy_of_test"
      ],
      "metadata": {
        "id": "rKst0t0LwxUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg19 = models.vgg19(pretrained=True)\n",
        "vgg19.classifier[6] = nn.Linear(4096, 100)\n",
        "\n",
        "# freeze all feature layers\n",
        "for param in vgg19.features.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "3e-rHTaGwn8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg19 = vgg19.to(device)\n",
        "\n",
        "test_accuracy = train_and_return_test_accuracy(vgg19)\n",
        "print(f'Test accuracy: {test_accuracy}')"
      ],
      "metadata": {
        "id": "Pge7VOzGwtfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mqoTP_yv4xJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_return_test_accuracy(model, total_epochs=5, step_lr=0.005):\n",
        "    \"\"\"Function for training a model on the training dataset and calculating its accuracy on a test dataset\"\"\"\n",
        "    # Setup for optimization with stochastic gradient descent\n",
        "    optimize = optim.SGD(model.parameters(), lr=step_lr, momentum=0.9)\n",
        "    calculate_loss = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Training loop\n",
        "    for current_epoch in range(total_epochs):\n",
        "        for batch_number, (input_data, labels) in enumerate(train_loader):\n",
        "            input_data = input_data.to(device)\n",
        "            labels = labels.to(device)\n",
        "            optimize.zero_grad()\n",
        "            prediction = model(input_data)\n",
        "            training_loss = calculate_loss(prediction, labels)\n",
        "            training_loss.backward()\n",
        "            optimize.step()\n",
        "        if (current_epoch + 1) % 1 == 0:\n",
        "            print(f'Training Epoch: {current_epoch + 1} \\tLoss: {training_loss.item():.6f}')\n",
        "\n",
        "    # Evaluation for accuracy on the test set\n",
        "    accurate_predictions = 0\n",
        "    total_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for input_data, labels in test_loader:\n",
        "            input_data = input_data.to(device)\n",
        "            labels = labels.to(device)\n",
        "            test_predictions = model(input_data)\n",
        "            _, highest_predictions = torch.max(test_predictions.data, 1)\n",
        "            total_predictions += 1\n",
        "            accurate_predictions += (highest_predictions == labels).sum().item()\n",
        "    accuracy_of_test = accurate_predictions / total_predictions\n",
        "    return accuracy_of_test"
      ],
      "metadata": {
        "id": "iWIhHuYk4uxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50 = models.resnet50(pretrained=True)\n",
        "resnet50.classifier[6] = nn.Linear(4096, 100)\n",
        "\n",
        "# freeze all feature layers\n",
        "for param in resnet50.features.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "6U68GmsVxm93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wKjegibr4tsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50 = resnet50.to(device)\n",
        "\n",
        "test_accuracy = train_and_return_test_accuracy(resnet50)\n",
        "print(f'Test accuracy: {test_accuracy}')"
      ],
      "metadata": {
        "id": "nZaDiEerxm36"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}