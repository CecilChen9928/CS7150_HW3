{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.models as models"
      ],
      "metadata": {
        "id": "TdeFQ47IYMUr"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('device:', device)"
      ],
      "metadata": {
        "id": "qtaYktpUYMS1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98f3003a-8a8a-400b-ad50-b9d082c72589"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Make sure the kaggle.json file is present.\n",
        "!ls -lha kaggle.json\n",
        "\n",
        "# Next, install the Kaggle API client.\n",
        "!pip install -q kaggle\n",
        "\n",
        "# The Kaggle API client expects the json file to be in ~/.kaggle,\n",
        "# so move it there.\n",
        "!rm -rf ~/.kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# This permissions change avoids a warning on Kaggle tool startup.\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKEgseh0z9_N",
        "outputId": "b3f6c1e5-8beb-424b-8d63-d22759d1bf14"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 69 Feb 11 08:29 kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d gpiosenka/sports-classification\n",
        "\n",
        "# You might want to unzip the dataset if it's compressed.\n",
        "!unzip sports-classification.zip >> /dev/null\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nt8gG65o0dT3",
        "outputId": "051053e7-3ae7-47f9-b509-106765479588"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading sports-classification.zip to /content\n",
            " 99% 421M/424M [00:17<00:00, 22.9MB/s]\n",
            "100% 424M/424M [00:17<00:00, 24.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),  # Resize images to the desired size\n",
        "    transforms.ToTensor(),           # Convert images to tensors\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize images\n",
        "])"
      ],
      "metadata": {
        "id": "e3hVn6l3YX7f"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yI2Trtte171u"
      },
      "outputs": [],
      "source": [
        "# train data loader and test data loader\n",
        "dataset = ImageFolder(root='./train', transform=transform)\n",
        "\n",
        "batch_size = 128\n",
        "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_dataset = ImageFolder(root='./test', transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_return_test_accuracy(model, num_epochs=30, learning_rate=0.005):\n",
        "\n",
        "    sgd_optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Iterative training process\n",
        "    for epoch in range(num_epochs):\n",
        "        for batch_index, (inputs, labels) in enumerate(train_loader):\n",
        "\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            sgd_optimizer.zero_grad()\n",
        "            predictions = model(inputs)\n",
        "            loss_value = criterion(predictions, labels)\n",
        "            loss_value.backward()\n",
        "            sgd_optimizer.step()\n",
        "\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f'Training Epoch: {epoch + 1} \\tLoss: {loss_value.item():.6f}')\n",
        "\n",
        "    # Evaluating accuracy on the test dataset\n",
        "    correct_predictions = 0\n",
        "    all_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            test_outputs = model(inputs)\n",
        "            _, preds = torch.max(test_outputs.data, 1)\n",
        "            all_samples += labels.size(0)\n",
        "            correct_predictions += (preds == labels).sum().item()\n",
        "\n",
        "    accuracy_on_test = correct_predictions / all_samples\n",
        "    return accuracy_on_test"
      ],
      "metadata": {
        "id": "vRqm2QawXcuX"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=False)\n",
        "# modify the last layer to fit the number of classes 100\n",
        "model.classifier[6] = nn.Linear(4096, 100)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "qS0IxCwEig5H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a051ef8a-f28d-4c46-8c5a-13108eeca224"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy = train_and_return_test_accuracy(model)"
      ],
      "metadata": {
        "id": "DTaPmfuGig1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf7fb517-f304-41d7-edb2-7c29c81ffdef"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Epoch: 10 \tLoss: 3.972022\n",
            "Training Epoch: 20 \tLoss: 2.374878\n",
            "Training Epoch: 30 \tLoss: 1.255746\n",
            "Test accuracy: 0.506 % \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Test accuracy: {100 * test_accuracy} % ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ia7GLc7madY6",
        "outputId": "c9423242-cc01-4d2f-d10c-1ef7038da938"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 50.6 % \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Transfer learning\n"
      ],
      "metadata": {
        "id": "F2dPnOwVudA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_return_test_accuracy(model, num_epochs=5, learning_rate=0.005):\n",
        "\n",
        "    sgd_optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Iterative training process\n",
        "    for epoch in range(num_epochs):\n",
        "        for batch_index, (inputs, labels) in enumerate(train_loader):\n",
        "\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            sgd_optimizer.zero_grad()\n",
        "            predictions = model(inputs)\n",
        "            loss_value = criterion(predictions, labels)\n",
        "            loss_value.backward()\n",
        "            sgd_optimizer.step()\n",
        "\n",
        "        if (epoch + 1) % 1 == 0:\n",
        "            print(f'Training Epoch: {epoch + 1} \\tLoss: {loss_value.item():.6f}')\n",
        "\n",
        "    # Evaluating accuracy on the test dataset\n",
        "    correct_predictions = 0\n",
        "    all_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            test_outputs = model(inputs)\n",
        "            _, preds = torch.max(test_outputs.data, 1)\n",
        "            all_samples += labels.size(0)\n",
        "            correct_predictions += (preds == labels).sum().item()\n",
        "\n",
        "    accuracy_on_test = correct_predictions / all_samples\n",
        "    return accuracy_on_test\n"
      ],
      "metadata": {
        "id": "aEqkJrDzigu9"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transfer learning\n",
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True)\n",
        "# modify the last layer to fit the number of classes 100\n",
        "model.classifier[6] = nn.Linear(4096, 100)\n",
        "\n",
        "# freeze all feature layers\n",
        "for param in model.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "test_accuracy = train_and_return_test_accuracy(model)\n",
        "print(f'Test accuracy: {100 * test_accuracy} % ')"
      ],
      "metadata": {
        "id": "FEO830KYwInt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ce4b361-e92b-4b1b-eb6a-331fe012b02b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100%|██████████| 233M/233M [00:01<00:00, 146MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Epoch: 1 \tLoss: 0.622307\n",
            "Training Epoch: 2 \tLoss: 0.625878\n",
            "Training Epoch: 3 \tLoss: 0.279085\n",
            "Training Epoch: 4 \tLoss: 0.628623\n",
            "Training Epoch: 5 \tLoss: 0.341436\n",
            "Test accuracy: 81.39999999999999 % \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Transfer learning based on vgg19\n"
      ],
      "metadata": {
        "id": "j14-PgThwoS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_return_test_accuracy(model, num_epochs=5, learning_rate=0.005):\n",
        "\n",
        "    sgd_optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Iterative training process\n",
        "    for epoch in range(num_epochs):\n",
        "        for batch_index, (inputs, labels) in enumerate(train_loader):\n",
        "\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            sgd_optimizer.zero_grad()\n",
        "            predictions = model(inputs)\n",
        "            loss_value = criterion(predictions, labels)\n",
        "            loss_value.backward()\n",
        "            sgd_optimizer.step()\n",
        "\n",
        "        if (epoch + 1) % 1 == 0:\n",
        "            print(f'Training Epoch: {epoch + 1} \\tLoss: {loss_value.item():.6f}')\n",
        "\n",
        "    # Evaluating accuracy on the test dataset\n",
        "    correct_predictions = 0\n",
        "    all_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            test_outputs = model(inputs)\n",
        "            _, preds = torch.max(test_outputs.data, 1)\n",
        "            all_samples += labels.size(0)\n",
        "            correct_predictions += (preds == labels).sum().item()\n",
        "\n",
        "    accuracy_on_test = correct_predictions / all_samples\n",
        "    return accuracy_on_test"
      ],
      "metadata": {
        "id": "rKst0t0LwxUM"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg19 = models.vgg19(pretrained=True)\n",
        "vgg19.classifier[6] = nn.Linear(4096, 100)\n",
        "\n",
        "# freeze all feature layers\n",
        "for param in vgg19.features.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "3e-rHTaGwn8S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d952755-22e6-40c1-911d-09e0daa53f25"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n",
            "100%|██████████| 548M/548M [00:03<00:00, 186MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg19 = vgg19.to(device)\n",
        "\n",
        "test_accuracy = train_and_return_test_accuracy(vgg19)\n",
        "print(f'Test accuracy: {100 * test_accuracy} % ')"
      ],
      "metadata": {
        "id": "Pge7VOzGwtfL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1214deaa-b89d-4742-d67c-85f9c1548bf6"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Epoch: 1 \tLoss: 0.851092\n",
            "Training Epoch: 2 \tLoss: 0.521460\n",
            "Training Epoch: 3 \tLoss: 0.484028\n",
            "Training Epoch: 4 \tLoss: 0.308592\n",
            "Training Epoch: 5 \tLoss: 0.299722\n",
            "Test accuracy: 91.8 % \n"
          ]
        }
      ]
    }
  ]
}